\begin{algorithmic}[1]
\Require{Autoencoder $(g_{\vc{\theta}}, e_{\vc{\phi}})$, a training set $X=\lbrace \vc{x}_1, \vc{x}_2, \ldots, \vc{x}_n \rbrace \subset \mathcal{X}$, maximum number of iterations $I\in\mathbb{N}$, batchsize $L \in \mathbb{N}$.}
\State $\vc{\phi},\vc{\theta} \gets $ Initialize weights
\State{$i \gets $ Iteration counter}
\While{$i<I$ or $\vc{\phi},\vc{\theta}$ are not converged}
	\State{$X_L \gets$ A random batch of $L$ samples from $X$}
	\State$l \gets \frac{1}{L}\sum_{i=1}^L \mathcal{L}_{\text{AE}}(\vc{x}_i,\vc{\phi},\vc{\theta}), \vc{x}_i \in X_L$
	\State$\vc{\phi} \stackrel{+}\gets - \nabla_{\vc{\phi}}l $ update of encoder weights
	\State$\vc{\theta} \stackrel{+}\gets - \nabla_{\vc{\theta}}l $ update of decoder weights
	\State{$i \gets i+1$}
\EndWhile
\State{\textbf{return} encoder $e_{\vc{\phi}}(\vc{x})$, decoder $g_{\vc{\theta}}(\vc{z})$}
\end{algorithmic}